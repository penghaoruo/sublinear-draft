\relax 
\citation{HastieBook:SL}
\citation{Vapnik:1998}
\citation{tsumoto2004mining}
\citation{genkin2007large}
\citation{page1999pagerank}
\citation{androutsopoulos2000evaluation}
\@writefile{toc}{\contentsline {title}{Massively Parallel Learning for Penalized Logistic Regression Model}{1}}
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{No Author Given}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:int}{{1}{1}}
\citation{white2012hadoop}
\citation{mahoutscalable}
\citation{zaharia2010spark}
\citation{borthakur2008hdfs}
\citation{dean2008mapreduce}
\citation{gropp1999using}
\citation{zhang2004solving}
\citation{xiao2010dual}
\citation{peng2012sublinear}
\citation{chang2011psvm}
\citation{wang2009plda}
\citation{le2011building}
\citation{kyrola2012graphchi}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}}
\newlabel{sec:rew}{{2}{2}}
\citation{white2012hadoop}
\citation{dean2008mapreduce}
\citation{mahoutscalable}
\citation{zaharia2010spark}
\citation{clarkson2010sublinear}
\citation{hazanbeating}
\citation{cotter2012kernelized}
\citation{hazan2011optimal}
\citation{garberapproximating}
\citation{peng2012sublinear}
\@writefile{toc}{\contentsline {section}{\numberline {3}Penalized Logistic Regression Models and Sublinear Methods}{5}}
\newlabel{sec:plr}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Penalized Logistic Regression Models}{5}}
\newlabel{eqn:4}{{1}{5}}
\citation{tibshirani1996regression}
\citation{arora2005multiplicative}
\citation{peng2012sublinear}
\newlabel{eqn:5}{{2}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sublinear Algorithms}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sequential Sublinear Algorithm for Logistic Regression}{6}}
\newlabel{sec:l2alg}{{3.3}{6}}
\citation{peng2012sublinear}
\newlabel{alg:1}{{3.3}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Parallel Framework of Learning Algorithms for PLR}{7}}
\newlabel{sec:framework}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Parallel Sublinear algorithms in Hadoop MapReduce}{8}}
\newlabel{fig:frame}{{4.1}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Parallel implementation flow chart for PSUBPLR-MR}}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Parallel Sublinear algorithms in Spark}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Parallel Gradient Descent in Spark}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Online Stochastic Gradient Descent in Mahout}{12}}
\citation{guyon2004result}
\citation{DelanyKBS05}
\citation{ma2009identifying}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments Setup}{13}}
\newlabel{sec:setup}{{5}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Datasets Information}{13}}
\citation{fan2008liblinear}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Datasets}}{14}}
\newlabel{tab:table1}{{1}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Cluster Information}{14}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Cluster Information}}{14}}
\newlabel{tab:table2}{{2}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Test Programs}{14}}
\newlabel{fig:02}{{6.1}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visual Result on Simulated \textbf  {2d} Dataset}}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experimental Results}{15}}
\newlabel{sec:experiment}{{6}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Results on Simulated 2d Dataset}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Results on Precision}{15}}
\newlabel{sec:precision}{{6.2}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Accuracy Results}}{15}}
\newlabel{tab:table3}{{3}{15}}
\newlabel{fig:03}{{6.2}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Test error, as a function of iteration number on Simulated \textbf  {2d} Dataset}}{16}}
\newlabel{fig:04}{{6.2}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Test error, as a function of iteration number on \textbf  {20NewsGroup} Dataset}}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Results on Running Time}{16}}
\newlabel{sec:time}{{6.3}{16}}
\newlabel{fig:05}{{6.2}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Test error, as a function of iteration number on \textbf  {Gisette} Dataset}}{17}}
\newlabel{fig:06}{{6.2}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Test error, as a function of iteration number on \textbf  {ECUESpam} Dataset}}{17}}
\newlabel{fig:07}{{6.2}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Test error, as a function of iteration number on \textbf  {URL-Reputation} Dataset}}{18}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Running Time Results}}{18}}
\newlabel{tab:table4}{{4}{18}}
\newlabel{fig:08}{{6.3}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces All running times}}{19}}
\newlabel{fig:09}{{6.4}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Running time, as a function of used node number on Simulated \textbf  {2d} Dataset}}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Results on Changing Cluster}{19}}
\newlabel{fig:10}{{6.4}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Running time, as a function of used node number on \textbf  {20NewsGroup} Dataset}}{20}}
\newlabel{fig:11}{{6.4}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Running time, as a function of used node number on \textbf  {Gisette} Dataset}}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Fault Tolerance}{20}}
\newlabel{fig:12}{{6.4}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Running time, as a function of used node number on \textbf  {ECUESpam} Dataset}}{21}}
\newlabel{fig:13}{{6.4}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Running time, as a function of used node number on \textbf  {URL-Reputation} Dataset}}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{21}}
\newlabel{sec:concl}{{7}{21}}
\bibstyle{plain}
\bibdata{mlpaper}
\bibcite{androutsopoulos2000evaluation}{1}
\bibcite{arora2005multiplicative}{2}
\bibcite{borthakur2008hdfs}{3}
\bibcite{chang2011psvm}{4}
\bibcite{clarkson2010sublinear}{5}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Fault Tolerance Analysis}}{22}}
\newlabel{tab:table5}{{5}{22}}
\newlabel{fig:14}{{6.5}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Iteration time, as a function of percentage of failed maps, on \textbf  {URL-Reputation} Dataset, run on 6 nodes}}{22}}
\bibcite{cotter2012kernelized}{6}
\bibcite{dean2008mapreduce}{7}
\bibcite{DelanyKBS05}{8}
\bibcite{fan2008liblinear}{9}
\bibcite{garberapproximating}{10}
\bibcite{genkin2007large}{11}
\bibcite{gropp1999using}{12}
\bibcite{guyon2004result}{13}
\bibcite{HastieBook:SL}{14}
\bibcite{hazan2011optimal}{15}
\bibcite{hazanbeating}{16}
\bibcite{kyrola2012graphchi}{17}
\bibcite{le2011building}{18}
\bibcite{ma2009identifying}{19}
\bibcite{mahoutscalable}{20}
\bibcite{page1999pagerank}{21}
\bibcite{peng2012sublinear}{22}
\bibcite{tibshirani1996regression}{23}
\bibcite{tsumoto2004mining}{24}
\bibcite{Vapnik:1998}{25}
\bibcite{wang2009plda}{26}
\bibcite{white2012hadoop}{27}
\bibcite{xiao2010dual}{28}
\bibcite{zaharia2010spark}{29}
\bibcite{zhang2004solving}{30}
